{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf95f980-2287-4549-b149-bcc1c919f9fb",
   "metadata": {},
   "source": [
    "This is my first attempt at writing code and calling an API outside of coursework.\n",
    "\n",
    "Out of curiosity: I will test OpenAI Playground and insert just the prompt section with prompt code settings to compare my code with \"View code\" from Playground IDE. \n",
    "\n",
    "For fun: I will try to get ChatGTP to create the entire code using a prompt. I will share the findings of my experiment at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a277a7c-33b3-4856-86f9-40dc14627962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03118d36-80ee-4d67-8594-bf74c88e4ef2",
   "metadata": {},
   "source": [
    "I imported dotenv library from pypi because I need all the help I can get.\n",
    "\n",
    "I used my OpenAI API key but replaced it with 'OPENAI_API_KEY' for public code. \n",
    "\n",
    "The following is a function for the completion set up using openai. Since I am designing a teacher prompt, I set temp to zero and top_p to 1 for the output/answer to be more conservative and probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf6c4e6-0516-42bb-bc28-62aa4c24f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_teacher(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=500,\n",
    "        top_p=1.0,\n",
    "        \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04649b4d-5100-4505-bc60-074b5c4327f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Setting a presence penalty refers to the act of assigning a negative value or penalty to a certain condition or action in a prompt engineering context. In prompt engineering, a presence penalty is used to discourage or penalize the model from generating certain types of outputs or behaviors.\n",
      "\n",
      "2. The problem that setting a presence penalty solves is to guide the model's behavior and ensure that it generates outputs that align with the desired outcome. By assigning a penalty, you can influence the model to avoid generating certain types of responses or outputs that may be undesirable or inappropriate.\n",
      "\n",
      "3. Use cases for setting a presence penalty can vary depending on the specific application or context. For example, in a chatbot scenario, you may want to set a presence penalty to discourage the model from generating offensive or inappropriate responses. In a code generation task, you may set a presence penalty to prevent the model from generating code snippets that are vulnerable to security risks.\n",
      "\n",
      "4. A real-life example of setting a presence penalty can be seen in content moderation systems used by social media platforms. These platforms often employ machine learning models to automatically detect and filter out offensive or harmful content. By setting a presence penalty, the models can be guided to avoid generating or promoting such content, thereby ensuring a safer and more positive user experience.\n"
     ]
    }
   ],
   "source": [
    "student_question = f\"\"\"\n",
    "When should I set a presence penalty?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Act as a python teacher who is teaching a course on prompt engineering for developers.\\\n",
    "A student will ask you a question deliminated by tripple quotes.\\\n",
    "You will respond to the student in four steps:\n",
    "1. Explain the answer. If there is technical terminology used, define the term.\n",
    "2. Explain what problem it solves.\n",
    "3. Provide use cases.\n",
    "4. Give a real-life example.\n",
    "\n",
    "\\\"\\\"\\\"{student_question}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = ai_teacher(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eedd42-2ba4-4fe3-839f-d3028d9459f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out of curiosity test\n",
    "#When I pasted the prompt into the IDE and hit View Code botton, here is the code:\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Act as a python teacher who is teaching a course on prompt engineering for developers.\\nA student will ask you a question deliminated by tripple quotes.\\nYou will respond to the student in four steps:\\n1. Explain the answer. If there is technical terminology used, define the term.\\n2. Explain what problem it solves.\\n3. Provide use cases.\\n4. Give a real-life example.\\n\\\"\\\"\\\"When should I set a presence penalty?\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=500,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059808b0-c605-47a7-b457-af298614b493",
   "metadata": {},
   "source": [
    "I discovered that the gpt-3.5-turbo model option was not available in OpenAI Playground, so I used davinci instead. The code simplified in Playground, but the trade-off is readability and the ease of editing the question. This does enable people who do not know how to code to generate code.\n",
    "\n",
    "Next, let's see if I can prompt ChatGPT to generate similar code!\n",
    "Here is my prompt:\n",
    "\n",
    "Your task is to write python code for a chat completion that contains the following instructions:\n",
    "\"\"Call on openai api. Connect with an API key.\n",
    "Set up a prompt in which the response must be highly accurate and widely accepted.\n",
    "The prompt contains a student asking the question \"When should I set a presence penalty\" and also provides directions on how a teacher would respond. The directions are \"Act as a python teacher that is teaching a course on prompt engineering for developers.  Respond to the student question in four steps:\n",
    "1. Explain the answer. If there is technical terminology used, define the term.\n",
    "2. Explain what problem it solves.\n",
    "3. Provide use cases.\n",
    "4. Give a real-life example.\"\"\n",
    "Do not include any prompt completion in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc684e8-72d6-4445-9d13-2f9806a70394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the ChatGPT code:\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "def generate_chat_prompt(student_question):\n",
    "    prompt = \"\"\"Student: When should I set a presence penalty?\\n\n",
    "    Teacher: Act as a Python teacher who is teaching a course on prompt engineering for developers. Respond to the student's question in four steps:\\n\n",
    "    1. Explanation: Please explain the answer to the student's question. If there is any technical terminology used, remember to define the term.\\n\n",
    "    2. Problem-solving: Explain what problem the presence penalty solves and why it is important in prompt engineering.\\n\n",
    "    3. Use cases: Provide examples of use cases where setting a presence penalty is beneficial in developing prompt-based applications.\\n\n",
    "    4. Real-life example: Give a real-life scenario or application where the presence penalty can be applied to improve the quality of generated responses.\\n\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "student_question = \"When should I set a presence penalty?\"\n",
    "chat_prompt = generate_chat_prompt(student_question)\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e095f-f39f-4bfe-b2eb-acbd6a3d6a99",
   "metadata": {},
   "source": [
    "After an hour of testing various prompts, I encountered challenges in getting ChatGPT to generate the desired code output. One particular challenge was that ChatGPT likely had a temperature set around 0.5, resulting in some outputs containing prompt code settings and others without. This made it quite difficult to generate the teacher directions within the prompt, and the code provided above is the closest output achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d85739-4ad9-4942-8066-efedcc9dd64a",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "\n",
    "Although writing my own code was not the fastest approach, I preferred it because it allows for easy editing of the student question and reusability of the prompt. \n",
    "\n",
    "While using the Playground can enable users to generate code without coding knowledge, the readability and editing of the prompt proved to be challenging.\n",
    "\n",
    "My attempts to generate code through ChatGPT proved to be time-consuming and did not yield the desired outputs.\n",
    "\n",
    "Overall, this experience has been enjoyable and informative!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

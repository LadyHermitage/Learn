{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDWd0grVVH6nz97SraIaOC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I have designed this prompt to simulate my conversations with friends who I have not spoken to in a while: \"Are you struggling, sustaining, or thriving? What would it take to get you to the next level?\"\n",
        "\n",
        "The reason I chose to create this prompt is to practice using a for loop in asking the questions. I will then store the responses in a variable to be referenced for the system prompt.\n",
        "\n",
        "My process for writing prompt development code as a non-engineer is unconventional, but it works. Here are the steps:\n",
        "\n",
        "1. I draw the flow of the interaction on paper between the program, OpenAI, and the user.\n",
        "2. I prompt ChatGPT to write Python code by describing step 1 in detail.\n",
        "3. I refer to my understanding of coding and leverage past code setups to make my first attempt in a JupyterLab notebook and run the code.\n",
        "4. I troubleshoot issues and keep troubleshooting until there are no errors.\n",
        "5. Once I have working code, I test and iterate until I am satisfied with the output.\n",
        "6. Then, I publish to GitHub and go for a walk to enjoy the warmth of the sun on my skin."
      ],
      "metadata": {
        "id": "vJlM1rYWQp7s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEcVOgc6PU27"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(messages, model=\"gpt-3.5-turbo\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=.5,\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "ZNagL133PbMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def status_questions():\n",
        "    responses = []\n",
        "    for question in [\"Are you struggling, sustaining, or thriving?\", \"What would it take to get you to the next level?\", \"What are your blockers?\"]:\n",
        "        responses.append(input(question))\n",
        "    return responses\n",
        "\n",
        "def reflection():\n",
        "    print(\"Let's take a moment to pause and look on life. Answer the following questions and then I will offer a reflection.\")\n",
        "    user_responses = status_questions()\n",
        "\n",
        "    # Check the first response and provide different outputs accordingly\n",
        "    if user_responses[0].lower() == \"thriving\":\n",
        "        print(\"It is good to hear you are thriving. That response is rare. We hope you take a moment to pause and appreciate this time in your life.\")\n",
        "    else:\n",
        "        # Construct the prompt using user responses\n",
        "        prompt = [{\"role\": \"system\", \"content\": \"Given the user responses, provide actionable advice to help them achieve the goals they provided in their responses. Consider the blockers they have provided.\"}]\n",
        "        for i, response in enumerate(user_responses, start=1):\n",
        "            prompt.append({\"role\": \"user\", \"content\": response})\n",
        "            prompt.append({\"role\": \"assistant\", \"content\": \"A reflection:\"})\n",
        "\n",
        "        # Call the OpenAI API to complete the prompt\n",
        "        response = get_completion(messages=prompt)\n",
        "\n",
        "        # Print the API completion text\n",
        "        print(\"\\nA reflection:\")\n",
        "        print(response.strip())\n",
        "\n",
        "reflection()"
      ],
      "metadata": {
        "id": "M4R0WaO8PfEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}